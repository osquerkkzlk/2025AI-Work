{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d70ff650-4ed7-4b6d-8c3c-f2810acd7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0dd7e1-d8d2-4387-affa-5a227058b900",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : (593994, 13)\n",
      "test shape : (254569, 12)\n",
      "orig shape : (20000, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>debt_to_income_ratio</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>gender</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education_level</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>grade_subgrade</th>\n",
       "      <th>loan_paid_back</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29367.99</td>\n",
       "      <td>0.084</td>\n",
       "      <td>736</td>\n",
       "      <td>2528.42</td>\n",
       "      <td>13.67</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>High School</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Other</td>\n",
       "      <td>C3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22108.02</td>\n",
       "      <td>0.166</td>\n",
       "      <td>636</td>\n",
       "      <td>4593.10</td>\n",
       "      <td>12.92</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Debt consolidation</td>\n",
       "      <td>D3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49566.20</td>\n",
       "      <td>0.097</td>\n",
       "      <td>694</td>\n",
       "      <td>17005.15</td>\n",
       "      <td>9.76</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>High School</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Debt consolidation</td>\n",
       "      <td>C5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46858.25</td>\n",
       "      <td>0.065</td>\n",
       "      <td>533</td>\n",
       "      <td>4682.48</td>\n",
       "      <td>16.10</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>High School</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Debt consolidation</td>\n",
       "      <td>F1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>25496.70</td>\n",
       "      <td>0.053</td>\n",
       "      <td>665</td>\n",
       "      <td>12184.43</td>\n",
       "      <td>10.21</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>High School</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Other</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n",
       "0   0       29367.99                 0.084           736      2528.42   \n",
       "1   1       22108.02                 0.166           636      4593.10   \n",
       "2   2       49566.20                 0.097           694     17005.15   \n",
       "3   3       46858.25                 0.065           533      4682.48   \n",
       "4   4       25496.70                 0.053           665     12184.43   \n",
       "\n",
       "   interest_rate  gender marital_status education_level employment_status  \\\n",
       "0          13.67  Female         Single     High School     Self-employed   \n",
       "1          12.92    Male        Married        Master's          Employed   \n",
       "2           9.76    Male         Single     High School          Employed   \n",
       "3          16.10  Female         Single     High School          Employed   \n",
       "4          10.21    Male        Married     High School          Employed   \n",
       "\n",
       "         loan_purpose grade_subgrade  loan_paid_back  \n",
       "0               Other             C3             1.0  \n",
       "1  Debt consolidation             D3             0.0  \n",
       "2  Debt consolidation             C5             1.0  \n",
       "3  Debt consolidation             F1             1.0  \n",
       "4               Other             D1             1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import file\n",
    "\n",
    "dir=r\".\\storage\\data\"\n",
    "train=pd.read_csv(os.path.join(dir,\"train.csv\"))\n",
    "test=pd.read_csv(os.path.join(dir,\"test.csv\"))\n",
    "sub_=pd.read_csv(os.path.join(dir,\"sample_submission.csv\"))\n",
    "orig=pd.read_csv(os.path.join(dir,\"loan_dataset_20000.csv\"))\n",
    "\n",
    "print(\"train shape :\", train.shape)\n",
    "print(\"test shape :\",test.shape)\n",
    "print(\"orig shape :\",orig.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035253ad-f0a6-4a70-bca4-6426cf4359c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'loan_paid_back'\n",
    "CATS = ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']\n",
    "BASE = [col for col in train.columns if col not in ['id', TARGET]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c438ad-8a33-4a0c-ae57-cc3ff5f9f5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 Features.\n"
     ]
    }
   ],
   "source": [
    "# Step_1\n",
    "from itertools import combinations\n",
    "\n",
    "INTER=[]\n",
    "\n",
    "for col1,col2 in combinations(BASE,2):\n",
    "    new_col_name=f\"{col1}_{col2}\"\n",
    "    INTER.append(new_col_name)\n",
    "    for df in [train,test,orig]:\n",
    "        df[new_col_name]=df[col1].astype(str)+\"_\"+df[col2].astype(str)\n",
    "\n",
    "print(f\"{len(INTER)} Features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "154581fe-bf8e-40ef-8646-1cd7cd39a1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22Features\n"
     ]
    }
   ],
   "source": [
    "ORIG=[]\n",
    "\n",
    "for col in BASE:\n",
    "    mean_map=orig.groupby(col)[TARGET].mean().reset_index(name=f\"orig_mean_{col}\")\n",
    "    train=train.merge(mean_map,on=col,how=\"left\")\n",
    "    test=test.merge(mean_map,on=col,how=\"left\")\n",
    "    ORIG.append(f\"orig_mean_{col}\")\n",
    "\n",
    "    count_map=orig.groupby(col).size().reset_index(name=f\"orig_count_{col}\")\n",
    "    train=train.merge(count_map,on=col,how=\"left\")\n",
    "    test=test.merge(count_map,on=col,how=\"left\")\n",
    "    ORIG.append(f\"orig_count_{col}\")\n",
    "\n",
    "print(f\"{len(ORIG) }Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab768bec-f773-40f1-a7ee-7d08299df300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 Features.\n"
     ]
    }
   ],
   "source": [
    "FEATURES = BASE + ORIG + INTER\n",
    "print(len(FEATURES), 'Features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40c40454-a323-4ae4-bcdc-ec7b05a25ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[FEATURES]\n",
    "y = train[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cae73a56-f5c2-4061-a0a2-984339b2dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "from sklearn.base import  BaseEstimator,TransformerMixin\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import catboost as cat\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3c1ad19-fe22-4e51-a7b9-4798b522be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TargetEncoder(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,cols_to_encode,aggs=[\"mean\"],cv=5,smooth=\"auto\",drop_original=False):\n",
    "        self.cols_to_encode=cols_to_encode\n",
    "        self.aggs=aggs\n",
    "        self.cv=cv\n",
    "        self.smooth=smooth\n",
    "        self.drop_original=drop_original\n",
    "        self.mappings_={}\n",
    "        self.global_stats={}\n",
    "\n",
    "    def fit(self,X,y):\n",
    "\n",
    "        temp_df=X.copy()\n",
    "        temp_df[\"target\"]=y\n",
    "\n",
    "        for agg_func in self.aggs:\n",
    "            self.global_stats[agg_func]=y.agg(agg_func)\n",
    "\n",
    "        for col in self.cols_to_encode:\n",
    "            self.mappings_[col]={}\n",
    "            for agg_func in self.aggs:\n",
    "                self.mappings_[col][agg_func]=temp_df.groupby(col)[\"target\"].agg(agg_func)\n",
    "        return self\n",
    "        \n",
    "    def transform(self,X):\n",
    "        X_transformed=X.copy()\n",
    "        for col in self.cols_to_encode:\n",
    "            for agg_func in self.aggs:\n",
    "                col_name=f\"TE_{col}_{agg_func}\"\n",
    "                X_transformed[col_name]=X_transformed[col].map(self.mappings_[col][agg_func])\n",
    "                X_transformed[col_name].fillna(self.global_stats[agg_func],inplace=True)\n",
    "        if self.drop_original:\n",
    "            X_transformed.drop(columns=self.cols_to_encode,inplace=True)\n",
    "\n",
    "        return X_transformed\n",
    "\n",
    "    def fit_transform(self,X,y):\n",
    "        self.fit(X,y)\n",
    "        encoded_features=pd.DataFrame(index=X.index)\n",
    "        kf=KFold(n_splits=self.cv,shuffle=True,random_state=42)\n",
    "        for train_idx,val_idx in kf.split(X,y):\n",
    "            X_train,y_train=X.iloc[train_idx],y.iloc[train_idx]\n",
    "            X_val=X.iloc[val_idx]\n",
    "\n",
    "            temp_df_train=X_train.copy()\n",
    "            temp_df_train[\"target\"]=y_train\n",
    "\n",
    "            for col in self.cols_to_encode:\n",
    "                for agg_func in self.aggs:\n",
    "                    col_name=f\"TE_{col}_{agg_func}\"\n",
    "                    fold_global_stats=y_train.agg(agg_func)\n",
    "                    mapping=temp_df_train.groupby(col)[\"target\"].agg(agg_func)\n",
    "                if agg_func==\"mean\":\n",
    "                    counts=temp_df_train.groupby(col)[\"target\"].count()\n",
    "                    m=self.smooth\n",
    "\n",
    "                    if m ==\"auto\":\n",
    "                        variance_between=mapping.var()\n",
    "                        avg_variance_within=temp_df_train.groupby(col)[\"target\"].var().mean()\n",
    "                        if variance_between>0:\n",
    "                            m=avg_variance_within/variance_between\n",
    "                        else:m=0\n",
    "                    smoothed_mapping=(counts*mapping+m*fold_global_stats)/(m+counts)\n",
    "                    encoded_values=X_val[col].map(smoothed_mapping)\n",
    "                else:\n",
    "                    encoded_values=X_val[col].map(mapping)\n",
    "                encoded_features.loc[X_val.index,col_name]=encoded_values.fillna(fold_global_stats)\n",
    "        X_transformed=X.copy()\n",
    "        X_transformed=pd.concat([X_transformed,encoded_features],axis=1)\n",
    "        if self.drop_original:\n",
    "            X_transformed.drop(columns=self.cols_to_encode,inplace=True)\n",
    "        return X_transformed\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87f9039b-faee-4066-9af3-29cbfd5dc4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This took a lot of time to code, but I've already finished and saved it as a  file, \n",
    "# which you can directly import to get the mapping.\n",
    "import joblib\n",
    "os.makedirs(\"./storage\",exist_ok=True)\n",
    "# joblib.dump(mapping, \"./storage/mapping.joblib\")\n",
    "mapping=joblib.load(\"./storage/mapping.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53b3de68-4714-4393-85d2-9000ddc98a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< 1/5 > is Encoding !\n",
      "< 2/5 > is Encoding !\n",
      "< 3/5 > is Encoding !\n",
      "< 4/5 > is Encoding !\n",
      "< 5/5 > is Encoding !\n",
      "mapping Created\n"
     ]
    }
   ],
   "source": [
    "# Pre-encoding the target can significantly reduce the time required for optuna optimization and regular training.\n",
    "cv,SEED=5,42\n",
    "kf=StratifiedKFold(n_splits=cv,random_state=SEED,shuffle=True)\n",
    "mapping=[]\n",
    "for i,(train_idx,val_idx) in enumerate(kf.split(train,train[TARGET])):\n",
    "    print(f\"< {i+1}/{cv} > is Encoding !\")\n",
    "\n",
    "    x_train,y_train=train.iloc[train_idx][FEATURES],train.iloc[train_idx][TARGET]\n",
    "    x_val,y_val=train.iloc[val_idx][FEATURES],train.iloc[val_idx][TARGET]\n",
    "    x_test=test[FEATURES]\n",
    "\n",
    "    TE=TargetEncoder(cols_to_encode=INTER,cv=5,smooth=\"auto\",aggs=[\"mean\"],drop_original=True)\n",
    "    x_train=TE.fit_transform(x_train,y_train)\n",
    "    x_val=TE.transform(x_val)\n",
    "    x_test=TE.transform(x_test)\n",
    "\n",
    "    mapping.append([(x_train,y_train),(x_val,y_val),x_test])\n",
    "print(\"mapping Created\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_py310",
   "language": "python",
   "name": "torch_gpu_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
